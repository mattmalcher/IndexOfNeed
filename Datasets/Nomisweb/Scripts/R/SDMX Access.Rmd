---
title: "SDMX"
author: "Matthew Malcher"
date: "29/11/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Load data handling libraries
At this point I will also load a few other useful libraries:
```{r}
library(dplyr) #for manipulating data frames
library(jsonlite)
library(httr) #for parsing URL
```

#  Load rsdmx
There is an R library for working with SDMX. NOMIS is included as a predefined data source! This looks like it might make things a bit easier, but I cant figure out how to take advantage of it. Fortunately you can also buld your own URL's and feed them to the `readSDMX` command provided by the library.
```{r }
library(rsdmx)
providers <- getSDMXServiceProviders();
as.data.frame(providers) %>% filter(agencyId=='NOMIS')
```

# Windows Issues
The script seems to have some issues when run on Windows 10 - I susepect this is to do with http/https and ssl RC4 being depracated. The following is an attempt to mess around with the RCurl settings to ignore certificate errors. I dont know if it works. 

According to serversniff.net nomisweb.co.uk does not support sslv3 or v2 and uses tls v1.2. This is corroborated by 
testing on UBUNTU:

* DOES NOT WORK:
 - curl -3 https://www.nomisweb.co.uk/api/v01/dataset/def.sdmx.xml?search=contenttype-sources-aps

* FINE:
 - curl https://www.nomisweb.co.uk/api/v01/dataset/def.sdmx.xml?search=contenttype-sources-aps
 - curl -tlsv1.2 https://www.nomisweb.co.uk/api/v01/dataset/def.sdmx.xml?search=contenttype-sources-aps

https://stackoverflow.com/questions/38130293/tls-v1-1-tls-v1-2-support-in-rcurl

Im not sure that libcurl as used by RCurl on windows supports TLS 1.2 the options then become either:

* updating libcurl and building Rcurl to use the updated version or 
* replacing Rcurl with something

## Replacing RCurl in readSDMX
We can index directly to the bit of readSDMX that we want to change:
```{r}
body(readSDMX)[[13]][[4]]
```

We can also edit this bit, putting in a call to httr instead of using RCurl.

```{r}
body(readSDMX)[[13]][[4]]<-quote({

    rsdmxAgent <- paste("rsdmx/", "rsdmx",  sep = "")

    req_content <- httr::GET(file, add_headers(`User-Agent` = rsdmxAgent))
    content<-  httr::content(req_content, "text")

    if (httr::http_error(req_content)) {stop("HTTP request failed with status: ", httr::http_status(req_content))}

})

body(readSDMX)[[13]][[4]]
```

```{r Rcurl with settings for https on windows}
# Setting the general Rcurl settings does not help - need to set them in the call withing readSDMX
# library(RCurl)
# curlprefs <- curlOptions(ssl.verifypeer=FALSE, ssl.verifyhost=FALSE)
# curlSetOpt(.opts=curlprefs, curl = getCurlHandle())

# Making your own version of the function with the desired curl options does not work because the function relies on being defined within a certain environment.
# source("readSDMX_win.R")

#Trace is a debugging function which lets you modify functions on the fly.
#https://curl.haxx.se/libcurl/c/CURLOPT_SSLVERSION.html

# trace(readSDMX, quote(if (isURL == FALSE) {
#     isXML <- !isRData
#     if (isXML) {
#         if (!file.exists(file)) 
#             stop("File ", file, "not found\n")
#         content <- readChar(file, file.info(file)$size)
#     }
# } else {
#   
#     rsdmxAgent <- paste("rsdmx/", as.character(packageVersion("rsdmx")),  sep = "")
#     
#     req_content <- httr::GET(file, add_headers(`User-Agent` = rsdmxAgent))
#     content<-  httr::content( req_content,"text")
#     
#     if (httr::http_error(req_content)) {stop("HTTP request failed with status: ", httr::http_status(req_content))}
#     
# }), at=13, print=T)
```


There are some common bits of info used in all requests: 
```{r}
# Define API access point
ap<-'https://www.nomisweb.co.uk/api/v01/dataset' 
cl<-'https://www.nomisweb.co.uk/api/v01/codelist' 

# Define the format of the data returned for data discovery and interrogation queries. 
# The rsdmx package allows SMDX in XML format to be read into data frames.
qformat <-'def.sdmx.xml'
```
Now, lets get started with the nomisweb API!

# Dataset Discovery

## Get info on all datasets available
With the following commands we can get a data frame with details of all the datasets available on NOMIS:
```{r}
get_all_dataset<-function(ap,qformat){
    queryUrl <- paste(ap,qformat,sep='/')
    all_data <- as.data.frame(readSDMX(queryUrl))
    return(all_data)
  }

# NomisDatasets <- get_all_dataset(ap,qformat)
```
This is quite a long list and takes some time to retrieve.

## Get info on a particular dataset
Alternatively, if we know which dataset we want then we can request just that:
```{r}

info_on_dataset <- function(ap,qformat,dataset){
  queryUrl<-paste0(paste(ap,dataset,sep='/'),'.',qformat)
  # print('Querying: ',queryUrl)
  SingleDataset <- as.data.frame(readSDMX(queryUrl))
  return(SingleDataset)
}

# info_NM_1_1 <- info_on_dataset(ap,qformat,'NM_1_1')

```

## Get Structure and Codelist Names
```{r}
# https://www.nomisweb.co.uk/api/v01/dataset/NM_7_1/def.htm

get_struct <- function(ap,qformat,dataset){
  
  queryUrl<-paste0(paste(ap,dataset,qformat,sep='/'))
  print(queryUrl)
  SingleDataset <- readSDMX(queryUrl,dsd=TRUE)
  
  # index into the SDMX and retrieve the dimensions object
  Dims <- SingleDataset@datastructures[1][[1]]@Components@Dimensions
  
  # iterate over it to extract the dimesions and the codelist names
  ref=list()
  code=list()
  for(i in 1:length(Dims)){
    ref<- append(ref,Dims[[i]]@conceptRef)
    code<- append(code,Dims[[i]]@codelist)
  }
  
  # create data frame of these
  return(do.call(rbind, Map(data.frame, Ref=ref, CodeList=code)))
}

# struct_NM_1_1 <- get_struct (ap,qformat,'NM_7_1')
```


## Get codelist for a particular part of a dataset structure
```{r}
# https://www.nomisweb.co.uk/api/v01/codelist/CL_1_1_ITEM.def.sdmx.xml

get_codelist <- function(cl,qformat,codelist){
  
  queryUrl<-paste0(paste(cl,codelist,sep='/'),'.',qformat)
  print(queryUrl)
  SingleDataset <- as.data.frame(readSDMX(queryUrl))
  return(SingleDataset)
}

# codelist<-get_codelist(cl,qformat,'CL_1_1_ITEM')
```



## List Content Types 
The datasets can be broken down by contenttype:
```{r}
get_content_types <- function(){
  # Get a JSON containing all contenttype id's which fall under the AnnotationTitle 'contenttype/sources' 
  # (which, as far as I can tell is all of them)
  # Note - this is not part of standard SDMX so json is used here.
  json_data <- fromJSON(txt="https://www.nomisweb.co.uk/api/v01/contenttype/sources.json")
  return(json_data$contenttype$item)
}

# ContentType <- get_content_types()
# select(ContentType, id, name)
```

## List Datasets by Content Type
Get a list of datasets of a particular content type:
```{r}
get_datasets_by_contenttype <- function(contenttype){
  queryUrl <- paste0('https://www.nomisweb.co.uk/api/v01/dataset/def.sdmx.xml?search=contenttype-sources-',contenttype)
  as.data.frame(readSDMX(queryUrl))
}

# jsa_datasets <- get_datasets_by_contenttype('jsa')
# jsa_datasets
```

This is analogous to the categories presented at: https://www.nomisweb.co.uk/query/select/getdatasetbytheme


# Dataset Interrogation

## Region Selection
Get a Table of available regions for a dataset:
```{r}

available_regions <- function(ap,qformat,dataset){
  qtype<-'geography'
  queryUrl<-paste0(paste(ap,dataset,qtype,sep='/'),'.',qformat)
  regionlist <- as.data.frame(readSDMX(queryUrl))
  return(regionlist)
}

# regions_NM_1_1<-available_regions(ap,qformat,'NM_1_1')

```

## Get Available Output Area Types
Get a Table of available output areas for a dataset within a region identified by its id
```{r}
available_OAs <- function(ap,qformat,dataset,regioncode){
  qtype<-'geography'
  queryUrl<-paste0(paste(ap,dataset,qtype,regioncode,sep='/'),'.',qformat)
  availableOAlist <- as.data.frame(readSDMX(queryUrl))
  return(availableOAlist)
}

# OAs_NM_1_1 <- available_OAs(ap,qformat,'NM_1_1','2092957697')
```

https://www.nomisweb.co.uk/forum/posts.aspx?tID=555&fID=2

## List of Output Areas
Get List of output areas for a given dataset, region and output area type
```{r}

list_OAs <- function(ap,qformat,dataset,regioncode,OAtype){
  qtype<-'geography'
  queryUrl<-paste0(paste(ap,dataset,qtype,regioncode,sep='/'),OAtype,'.',qformat)
  OAlist <- as.data.frame(readSDMX(queryUrl))
  OAlist<-rename(OAlist, GEOGRAPHY=id) # Rename the id column to GEOGRAPHY to match output of 
  return(OAlist)
}

# OAlist_NM_1_1 <- list_OAs(ap,qformat,'NM_1_1','2092957697','TYPE464')

```

## List Genders
Get a Table of available sex information for a dataset
```{r}
get_genders <-function(ap,dataset,qformat){
  qtype<-'sex'
  queryUrl<-paste0(paste(ap,dataset,qtype,sep='/'),'.',qformat)
  genders <- as.data.frame(readSDMX(queryUrl))
  return(genders)
}

# genders_NM_1_1 <- get_genders(ap,'NM_1_1', qformat)

```

## List Measures
Get the measures available for a given geography - these are denominators - i.e. out of the number of claimints, the number of people living there etc.
```{r}
get_measures <- function(ap,qformat,dataset,regioncode,OAtype){
  
  qtype<-'measures'
  queryUrl<-paste0(paste(ap,dataset,qtype,regioncode,sep='/'),OAtype,'.',qformat)
  print(queryUrl)
  measures <- as.data.frame(readSDMX(queryUrl))
  return(measures)
}

# measures_NM_1_1 <- get_measures(ap,qformat,'NM_1_1','2092957697','TYPE464')
```

## List Items
Get available 'items' for a specified dataset (i.e. the variables)
```{r}
get_items <- function(ap,dataset,qformat){
  
  qtype<-'item'
  queryUrl<-paste0(paste(ap,dataset,qtype,sep='/'),'.',qformat)
  AvailableItems <- as.data.frame(readSDMX(queryUrl))
  return(AvailableItems)
}

# items_NM_1_1 <- get_items(ap,'NM_1_1',qformat)
```

## List Times
Get available 'times' for a specified dataset 
```{r}
get_times <- function(ap,dataset,qformat){
  qtype<-'time'
  queryUrl<-paste0(paste(ap,dataset,qtype,sep='/'),'.',qformat)
  AvailableTimes <- as.data.frame(readSDMX(queryUrl))
  return(AvailableTimes)
}

# times_NM_1_1 <- get_times(ap,'NM_1_1',qformat)
```

# Getting Data
Once you have all the information and have decided on your geography, gender, measure, item and time then you can retrieve the data.
Get available 'items' for a specified dataset (i.e. the variables)

Define a function which takes a list of input arguments and builds them to make a url.
```{r}
get_data_sdmx <- function(qlist, dataset){
  dformat<- 'compact.sdmx.xml' # For some reason if I use generic.sdmx.xml I get back partial XML   files? Using compact sdmx gives a URI error but seems to return the correct data
  qurl=parse_url('https://www.nomisweb.co.uk/')
  qurl$path<-paste0('api/v01/',dataset,'.',dformat)
  qurl$query<-qlist
  
  queryUrl<-build_url(url=qurl)
  print(queryUrl)
  
  df <- as.data.frame(readSDMX(queryUrl))
  return(df)
}
# qlist<-list(geography='2038432081',sex=5,item=1,measures=20100,time='latest')
# exampledata<-get_data(qlist, 'NM_1_1')
```

# Tidy Data
This function lets you use the contents of a codelist to rename the ambiguous column names of a data frame which has been manipulated using spread to a wide format.
```{r}
reaname_via_codelist<- function(df,codeliststring){
  
  # Get the Names of the Data Frame
  names<- names(df)
  
  # Get the code list using the codelist string
  codelist <- get_codelist(cl,qformat,codeliststring) 
  
  # Filter the codelist to the names in your data frame
  codelist<- codelist %>% filter(id %in% names)
  
  # Append Geography since it wont be there but we want it to have a name 
  codelist<- rbind(codelist,data.frame(id = "GEOGRAPHY", label.en = "GEOGRAPHY"))
  
  # Generate a list of names we want to use
  rename_map <- as.character(codelist$label)
  names(rename_map) <- codelist$id    
    
  # Set the names of the cols in the data frame to the values in the rename map
  names(df) <- rename_map[names(df)]
  
  return(df)
}
```



```{r}
# ContentType <- get_content_types()

aps_datasets <- get_datasets_by_contenttype('aps')
```

